import os
from code_analyzer import CodeAnalyzer
from graphbuilder import GraphBuilder
from vector_store import VectorStore

from typing import List, Tuple,Annotated, TypedDict
import operator

from langgraph.graph import StateGraph, END
from langgraph.graph.state import CompiledStateGraph
from langchain_text_splitters import Language as SpliterLanguage



class CodeAnalysisState(TypedDict):
    file_map : Annotated[List[Tuple], "æ–‡ä»¶è·¯å¾„åˆ°ä»£ç æ˜ å°„", operator.add]
    entities : Annotated[List[Tuple], "ç±»å®žä½“", operator.add]
    language : str
    repo_path : str
    rst : bool=False
    ast_vector_gen:bool=False
    mermaid_gen:bool=False
    framework_anlayzed:bool=False
    security_anlayzed:bool=False
    performance_anlayzed:bool=False
    scalability_anlayzed:bool=False
    smell_anlayzed:bool=False

def globSuffix(language: str) -> str:
    return  {
        SpliterLanguage.LUA:"**/*.lua",
        SpliterLanguage.PYTHON:"**/*.py",
        SpliterLanguage.JAVA:"**/*.java",
        SpliterLanguage.CSHARP:"**/*.cs"
    }.get(language, "**/*.*")

def scan_directory(state: CodeAnalysisState) -> CodeAnalysisState:
    """æ‰«æå·¥ç¨‹ç›®å½•"""
    print("ðŸš€ æ‰«æå·¥ç¨‹ç›®å½•...")
    
    from langchain_community.document_loaders import TextLoader,DirectoryLoader
    
    repo_path = state.get("repo_path")
    language = state.get("language")
    
    loader = DirectoryLoader(repo_path, glob=globSuffix(language), recursive=True,show_progress=True, loader_cls=TextLoader, loader_kwargs={"autodetect_encoding":True})
    docs = loader.load()
     # è¿‡æ»¤æŽ‰ç©ºæ–‡ä»¶
    non_empty_docs = [doc for doc in docs if doc.page_content.strip()]

    
    return {"file_map": [(doc.metadata['source'], doc.page_content) for doc in non_empty_docs]}

def parallel_parse(state: CodeAnalysisState) -> CodeAnalysisState:
    """å¹¶è¡Œè§£æžæ‰€æœ‰æ–‡ä»¶"""
    print("ðŸ‘¥ å¹¶è¡Œè§£æžæ‰€æœ‰æ–‡ä»¶...")
    repo_path = state.get("repo_path", "")
    filemap  = state.get("file_map", [])
    language = state.get("language")
    analyzer = CodeAnalyzer(repo_path)
    
    results = []

    for path, content in filemap:
        result:List[Tuple] = analyzer.parse_file(path, content, language)
        if len(result[0][1]) == 0:
            continue
        results.append(result)

    return {"entities": [item for sublist in results for item in sublist]}


def build_relations(state: CodeAnalysisState) -> CodeAnalysisState:
    """æž„å»ºè°ƒç”¨å…³ç³»å›¾è°±"""
    from tqdm import tqdm
    import pprint
    
    print("ðŸ”¨ æž„å»ºè°ƒç”¨å…³ç³»å›¾è°±...")
    gb_inherit = GraphBuilder()
    gb_call = GraphBuilder()
    gb_depend = GraphBuilder()
    
    entities = state.get("entities", [])
    for filePath, clsInfos in entities:
        for clsInfo in clsInfos:
            clsName = clsInfo['class_name']
            
            # å¤„ç†ç»§æ‰¿å…³ç³»
            for parent in clsInfo['class_parent']:
                gb_inherit.add_relation(clsName, parent, 'inherit', filePath)
            
            # å¤„ç†æ–¹æ³•è°ƒç”¨
            for calling in clsInfo['class_method_calls']:
                gb_call.add_relation(clsName, calling[0], 'call', filePath)
                
            # å¤„ç†ä¾èµ–å…³ç³»
            for depend in clsInfo['class_dependencies']:
                gb_depend.add_relation(clsName, depend, 'depend', filePath)
                

    
    pretty_data = pprint.pformat(entities)
    relationFile = os.getenv("AST_RELATION_PATH")
    with open(relationFile, 'w') as f:
        f.write(pretty_data)
    
    # ç”Ÿæˆäº¤äº’å¼å¯è§†åŒ–
    gb_inherit.visualize_pyvis(os.getenv("INHERIT_GRAPH"))
    # ç”Ÿæˆäº¤äº’å¼å¯è§†åŒ–
    gb_call.visualize_pyvis(os.getenv("CALL_GRAPH"))
    # ç”Ÿæˆäº¤äº’å¼å¯è§†åŒ–
    gb_depend.visualize_pyvis(os.getenv("DEPEND_GRAPH"))

    print("ðŸ”¨ æž„å»ºä»£ç ASTå‘é‡åº“...")
    vector_store = VectorStore()
    vector_store.get_collection(os.getenv("AST_VECTORAB"), True)
    
    for path, class_infos in tqdm(entities, desc="è®°å½•ASTå…³ç³»å›¾è°±"): # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        for class_info in class_infos:
            pretty_data = pprint.pformat(class_info)
            embedding = vector_store.model.encode(pretty_data).tolist()
            # æž„å»ºå”¯ä¸€çš„ IDï¼Œé˜²æ­¢é‡å¤æ·»åŠ   
            doc_id = str(hash(path+class_info['class_name'])) 
            vector_store.add_to_chromadb(embedding, doc_id, metadata={
                "filePath" : path,
                "className" : class_info['class_name'],
                "classFields" : pprint.pformat(class_info['class_fields']) if len(class_info['class_fields']) > 0 else "None",
                "classMethods" : pprint.pformat(class_info['class_methods']) if len(class_info['class_methods']) > 0 else "None",
                "classProperties" : pprint.pformat(class_info['class_properties']) if len(class_info['class_properties']) > 0 else "None",
                "classParent" : pprint.pformat(class_info['class_parent']) if len(class_info['class_parent']) > 0 else "None",
                "classMethodCalls" : pprint.pformat(class_info['class_method_calls']) if len(class_info['class_method_calls']) > 0 else "None",
                "classDependencies" : pprint.pformat(class_info['class_dependencies']) if len(class_info['class_dependencies']) > 0 else "None"
            })
    
    return {"ast_vector_gen": True}


def generate_mermaid(state: CodeAnalysisState) -> CodeAnalysisState:
    """ç”Ÿæˆæ–‡æ¡£å’Œå¯è§†åŒ–"""
    print("ðŸ“ ç”Ÿæˆä»£ç æž¶æž„åˆ†æžæ–‡æ¡£...")
    from agents.mermaid_generator import mermaid_generator,save_mermaid_file
    
    query = "æœç´¢æ‰€æœ‰class_parentåŠclass_dependenciesä¸ä¸ºNoneçš„ç±»ä¿¡æ¯"  # æŸ¥è¯¢è¯­å¥  

    vector_store = VectorStore()
    vector_store.get_collection(os.getenv("AST_VECTORAB"), True)
    mermaid_code = mermaid_generator(query, vector_store.collection, vector_store.model)  # ç”Ÿæˆ Mermaid ä»£ç   
    save_mermaid_file(mermaid_code)  # ä¿å­˜ Mermaid ä»£ç åˆ°æ–‡ä»¶
    
    return {"mermaid_gen": True}

def analyze_framework(state: CodeAnalysisState) -> CodeAnalysisState:
    print("ðŸ” åˆ†æžæ¡†æž¶ç»“æž„...")
    from agents.framework_analyzer import framework_analyzer
    rst = framework_analyzer()
    
    with open(os.getenv("FRAMEWORK_ANALYSIS_PATH"), "w", encoding="utf-8") as f:
        f.write(rst)
        
    return {"framework_anlayzed":True}

def analyze_security(state: CodeAnalysisState) -> CodeAnalysisState:
    print("ðŸ” åˆ†æžä»£ç å®‰å…¨æ¼æ´ž...")
    return {"security_anlayzed":True}

def analyze_performance(state: CodeAnalysisState) -> CodeAnalysisState:
    print("ðŸ” åˆ†æžä»£ç æ€§èƒ½...")
    return {"performance_anlayzed":True}

def analyze_scalability(state: CodeAnalysisState) -> CodeAnalysisState:
    print("ðŸ” åˆ†æžä»£ç å¯æ‰©å±•æ€§...")
    return {"scalability_anlayzed":True}

def analyze_smell(state: CodeAnalysisState) -> CodeAnalysisState:
    print("ðŸ” åˆ†æžä»£ç å¼‚å‘³...")
    
    return {"smell_anlayzed":True}

def generate_report(state: CodeAnalysisState) -> CodeAnalysisState:
    print("ðŸ“„ ç”Ÿæˆä»£ç åˆ†æžæŠ¥å‘Š...")
    return {"rst":True}

def endScan(state: CodeAnalysisState) -> CodeAnalysisState:
    if len(state["file_map"]) == 0:
        print("âŒ æž„å»ºä»£ç æ˜ å°„å¤±è´¥ï¼")
        return END
    return "parse"
def endParse(state: CodeAnalysisState) -> CodeAnalysisState:
    if len(state["entities"]) == 0:
        print("âŒ æž„å»ºå›¾è°±å®žä½“å¤±è´¥ï¼")
        return END
    return "build_graph"
def endBuildGraph(state: CodeAnalysisState) -> CodeAnalysisState:
    if state.get("ast_vector_gen", False):
        print("âŒ æž„å»ºå›¾è°±å…³ç³»å¤±è´¥ï¼")
        return END
    return "generate_mermaid"
def endGenerateMermaid(state: CodeAnalysisState) -> CodeAnalysisState:
    if state.get("mermaid_gen", False):
        print("âŒ ç”Ÿæˆ Mermaid æ–‡ä»¶å¤±è´¥ï¼")
        return END
    return "analyze_framework"



def create_workflow() -> CompiledStateGraph:
    
    workflow = StateGraph(CodeAnalysisState)

    workflow.add_node("scan", scan_directory)
    workflow.add_node("parse", parallel_parse)
    workflow.add_node("build_graph", build_relations)
    workflow.add_node("generate_mermaid", generate_mermaid)
    workflow.add_node("analyze_framework", analyze_framework)
    workflow.add_node("analyze_security", analyze_security)
    workflow.add_node("analyze_performance", analyze_performance)
    workflow.add_node("analyze_scalability", analyze_scalability)
    workflow.add_node("analyze_smell", analyze_smell)
    workflow.add_node("generate_report", generate_report)

    workflow.set_entry_point("scan")
    workflow.add_conditional_edges("scan", endScan)
    workflow.add_conditional_edges("parse", endParse)
    workflow.add_conditional_edges("build_graph", endBuildGraph)
    workflow.add_conditional_edges("generate_mermaid", endGenerateMermaid)
    workflow.add_edge("generate_mermaid", END)

    app = workflow.compile()
    return app